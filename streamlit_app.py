import streamlit as st
import openai
import tempfile

# âœ… í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="GPT ì±—ë´‡ í†µí•©", layout="centered")
st.title("ğŸ¤– GPT ì±—ë´‡ í†µí•© í˜ì´ì§€")

# âœ… OpenAI API Key ì…ë ¥
api_key = st.text_input("ğŸ”‘ OpenAI API Keyë¥¼ ì…ë ¥í•˜ì„¸ìš”", type="password")
if api_key:
    st.session_state["api_key"] = api_key

# âœ… ë„ì„œê´€ ê·œì • ë¶ˆëŸ¬ì˜¤ê¸°
@st.cache_data
def load_rules():
    try:
        with open("library_rules.txt", "r", encoding="utf-8") as f:
            return f.read()
    except FileNotFoundError:
        return "ë„ì„œê´€ ê·œì • íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

library_rules = load_rules()

# âœ… íƒ­ êµ¬ì„±
tab1, tab2, tab3 = st.tabs(["ğŸ§  ì¼ë°˜ GPT ì±—ë´‡", "ğŸ“š ë¶€ê²½ëŒ€ ë„ì„œê´€ ì±—ë´‡", "ğŸ“„ ChatPDF ì±—ë´‡"])

# ---------------------------- 1. ì¼ë°˜ ì±—ë´‡ ----------------------------
with tab1:
    st.subheader("ğŸ§  GPT-4.1-mini ì¼ë°˜ ì±—ë´‡")

    if "chat_history_general" not in st.session_state:
        st.session_state.chat_history_general = []

    user_input = st.text_input("ğŸ’¬ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš” (ì¼ë°˜)", key="general_input")

    @st.cache_data(show_spinner="GPTì—ê²Œ ë¬»ëŠ” ì¤‘...")
    def get_gpt_response(api_key, messages):
        client = openai.OpenAI(api_key=api_key)
        response = client.chat.completions.create(
            model="gpt-4.1-mini",
            messages=messages
        )
        return response.choices[0].message.content

    if st.button("ì¼ë°˜ ì±—ë´‡ ì‘ë‹µ ë°›ê¸°") and user_input and "api_key" in st.session_state:
        st.session_state.chat_history_general.append({"role": "user", "content": user_input})
        reply = get_gpt_response(api_key, st.session_state.chat_history_general)
        st.session_state.chat_history_general.append({"role": "assistant", "content": reply})

    if st.button("ğŸ”„ ì¼ë°˜ ì±—ë´‡ ì´ˆê¸°í™”"):
        st.session_state.chat_history_general = []

    st.write("### ğŸ’¬ ì¼ë°˜ ì±—ë´‡ ëŒ€í™” ë‚´ìš©")
    for msg in st.session_state.chat_history_general:
        speaker = "ğŸ‘¤ ì‚¬ìš©ì" if msg["role"] == "user" else "ğŸ¤– GPT"
        st.markdown(f"**{speaker}:** {msg['content']}")

# ---------------------------- 2. ë„ì„œê´€ ì±—ë´‡ ----------------------------
with tab2:
    st.subheader("ğŸ“š ë¶€ê²½ëŒ€ ë„ì„œê´€ ì±—ë´‡")

    if "chat_history_library" not in st.session_state:
        st.session_state.chat_history_library = []

    question = st.text_input("âœï¸ ë„ì„œê´€ ê´€ë ¨ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”", key="library_input")

    @st.cache_data(show_spinner="ë„ì„œê´€ ì±—ë´‡ì´ ë‹µë³€ ì¤‘ì…ë‹ˆë‹¤...")
    def ask_library_bot(api_key, question, rules):
        client = openai.OpenAI(api_key=api_key)
        system_prompt = (
            "ë‹¹ì‹ ì€ êµ­ë¦½ë¶€ê²½ëŒ€í•™êµ ë„ì„œê´€ ê·œì •ì„ ì˜ ì•„ëŠ” ë„ì„œê´€ ì±—ë´‡ì…ë‹ˆë‹¤.\n"
            "ì•„ë˜ ê·œì •ì„ ì°¸ê³ í•˜ì—¬ ì‚¬ìš©ì ì§ˆë¬¸ì— ë‹µë³€í•˜ì„¸ìš”.\n\n"
            f"[ë„ì„œê´€ ê·œì •]\n{rules}"
        )
        response = client.chat.completions.create(
            model="gpt-4.1-mini",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": question}
            ]
        )
        return response.choices[0].message.content

    if st.button("ë„ì„œê´€ ì±—ë´‡ ì‘ë‹µ ë°›ê¸°") and question:
        answer = ask_library_bot(api_key, question, library_rules)
        st.session_state.chat_history_library.append(("ğŸ‘¤ ì‚¬ìš©ì", question))
        st.session_state.chat_history_library.append(("ğŸ¤– ì±—ë´‡", answer))

    if st.button("ğŸ”„ ë„ì„œê´€ ì±—ë´‡ ì´ˆê¸°í™”"):
        st.session_state.chat_history_library = []

    st.write("### ğŸ’¬ ë„ì„œê´€ ì±—ë´‡ ëŒ€í™” ë‚´ìš©")
    for speaker, msg in st.session_state.chat_history_library:
        st.markdown(f"**{speaker}:** {msg}")

# ---------------------------- 3. ChatPDF ì±—ë´‡ ----------------------------
with tab3:
    st.subheader("ğŸ“„ ChatPDF ê¸°ë°˜ ì±—ë´‡")

    # íŒŒì¼ ì—…ë¡œë“œ
    uploaded_file = st.file_uploader("ğŸ“ PDF íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”", type="pdf")

    if "pdf_file_id" not in st.session_state:
        st.session_state["pdf_file_id"] = None

    # íŒŒì¼ ì—…ë¡œë“œ ì²˜ë¦¬
    if uploaded_file and api_key:
        client = openai.OpenAI(api_key=api_key)
        with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp:
            tmp.write(uploaded_file.read())
            tmp_path = tmp.name

        # ì—…ë¡œë“œ ë° íŒŒì¼ ID ì €ì¥
        with open(tmp_path, "rb") as f:
            file = client.files.create(file=f, purpose="assistants")
            st.session_state["pdf_file_id"] = file.id
            st.success(f"âœ… íŒŒì¼ ì—…ë¡œë“œ ì™„ë£Œ! íŒŒì¼ ID: {file.id}")

    # ì§ˆë¬¸ ì…ë ¥
    pdf_question = st.text_input("ğŸ“– PDFì— ëŒ€í•´ ì§ˆë¬¸í•˜ì„¸ìš”")

    if pdf_question and st.session_state.get("pdf_file_id"):
        st.write("ì§ˆë¬¸ ì²˜ë¦¬ ì¤‘...")

        response = client.chat.completions.create(
            model="gpt-4-1106-preview",
            messages=[
                {
                    "role": "system",
                    "content": "ë‹¹ì‹ ì€ ì—…ë¡œë“œëœ PDFë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µí•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤."
                },
                {"role": "user", "content": pdf_question}
            ],
            tools=[{"type": "file_search"}],
            tool_choice="auto",
            file_ids=[st.session_state["pdf_file_id"]]
        )
        st.markdown("**ğŸ¤– GPT ì‘ë‹µ:**")
        st.write(response.choices[0].message.content)

    # ë²¡í„° ìŠ¤í† ì–´ ì´ˆê¸°í™”
    if st.button("ğŸ§¹ Clear PDF íŒŒì¼"):
        if st.session_state.get("pdf_file_id"):
            client.files.delete(st.session_state["pdf_file_id"])
            st.success("ğŸ“ ì—…ë¡œë“œëœ PDF íŒŒì¼ì´ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.")
            st.session_state["pdf_file_id"] = None
